{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for HMTC - Hierarchical Multi-label classification of Privacy Policies.\n",
    "\n",
    "Code for reproducing results in the paper \"A Combined Rule-Based and Machine Learning Approach for Automated GDPR Compliance Checking\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a local multi-label classifier for the higher level to predict categories and one local multi-label classifier per attribute to predict their values. In total, one classifier is trained for the first level, and 20 classifiers are trained for the lower level.\n",
    "\n",
    "This approach is inspired by the work of [Polisis](https://arxiv.org/abs/1802.02561) where they constructed a multi-label classifier for the first level of the hierarchy to predict the categories of data practices from an input segment. Once the categories of a segment are predicted, the second step consists in predicting the values of attributes children of the predicted categories. For example, if the first-level classifier predicts the categories *Data Retention* and  *Data Security* then only the local classifiers that correspond to the attributes *Retention Period, Retention Purpose, Personal Information Type, Security Measure* are considered to predict their values. \n",
    "\n",
    "Authors of Polisis [Polisis](https://arxiv.org/abs/1802.02561) are using the same base classifier for all the multi-label classifiers. In this paper we reproduce their work by using CNN as the same base classifiers. We use the same architecture of CNN  and hyperparameters. The CNN classifier is composed of one convolutional layer with a ReLU activation, followed with a dense layer and a ReLU activation. The last layer is a dense layer with a sigmoid activation. We tokenize segments using PENN Treebank tokenization in NLTK. Tokens are mapped into a k-dimensional space via an embedding Layer. We used FastText to train Word embeddings* on 130,326 privacy policies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T09:54:14.394500Z",
     "start_time": "2021-05-11T09:54:14.385936Z"
    }
   },
   "source": [
    "\\* *Important Note: By default the code will use FastText in-domain embeddings. Due to licesing these embeddings can be provided only upon request.However GloVe embeddings can be used to run this code as well.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not have fastcore or fastprogress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T14:29:24.311471Z",
     "start_time": "2021-05-11T14:29:24.271884Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install fascore and fastprogress \n",
    "# !pip install fastcore\n",
    "# !pip install fastprogress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:45:10.554295Z",
     "start_time": "2021-05-11T11:45:09.094891Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# IN THE MAIN PATH\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Imports needed from pytorch\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "#Some built-in imports\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "#Imports from the repository\n",
    "from data_utils.labels import labels_dict\n",
    "from data_utils.data_processing import get_vocab, tokenize_sentence, process_dataset, create_multi_labels, stack_segments\n",
    "from data_utils.data_extraction import load_data, label_to_vector, load_attr_cat_data, load_category_data, load_obj, save_obj,unpickle_dataset\n",
    "from data_utils.data_collator import DataCollator\n",
    "from data_utils.ppd_dataset import PrivacyPoliciesDataset\n",
    "from model_nn.model_utils import get_emb_weights, extract_from_model_file, get_pretrained_embs, init_weights\n",
    "from model_nn.model_nn import HierarchicalModel\n",
    "from model_nn.model_nn import ParentCategoryModel\n",
    "from model_trainer import Trainer\n",
    "from evaluation.f1_score import f1_score, f1_score_per_label\n",
    "from evaluation.show_results import print_results, print_results_best_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define paths and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:45:10.589195Z",
     "start_time": "2021-05-11T11:45:10.557540Z"
    }
   },
   "outputs": [],
   "source": [
    "path = Path('.')\n",
    "\n",
    "# ATTRS\n",
    "emb_dim=300\n",
    "\n",
    "# Whether to use parent information or not\n",
    "parent_information=True\n",
    "\n",
    "if parent_information:\n",
    "    attr_data_path = path/'data/child_parent'\n",
    "else:\n",
    "    attr_data_path = path/'data/child_only'\n",
    "    \n",
    "raw_data_path = path/'data/category'\n",
    "fasttext_model = path/'fasttext/fastText-0.1.0/corpus_vectors_default_300d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the vocab and data from the CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:48:25.111056Z",
     "start_time": "2021-05-11T11:48:24.715294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 unique categories found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>segment</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Published: January 1, 2015</td>\n",
       "      <td>Introductory/Generic</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The WP Company LLC (The Washington Post) recog...</td>\n",
       "      <td>Introductory/Generic</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The WP Company LLC (The Washington Post) recog...</td>\n",
       "      <td>Practice not covered</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>This Privacy Policy covers the following:   Ho...</td>\n",
       "      <td>Introductory/Generic</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Information We Collect    We may collect pers...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                            segment  \\\n",
       "0    0                       Published: January 1, 2015     \n",
       "1    1  The WP Company LLC (The Washington Post) recog...   \n",
       "2    1  The WP Company LLC (The Washington Post) recog...   \n",
       "3    2  This Privacy Policy covers the following:   Ho...   \n",
       "4    3   Information We Collect    We may collect pers...   \n",
       "\n",
       "                     category  \\\n",
       "0        Introductory/Generic   \n",
       "1        Introductory/Generic   \n",
       "2        Practice not covered   \n",
       "3        Introductory/Generic   \n",
       "4  First Party Collection/Use   \n",
       "\n",
       "                                               label  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_category_df, train_categories_dict = load_category_data(raw_data_path / \"train\")\n",
    "validation_category_df, validation_categories_dict = load_category_data(raw_data_path / \"validation\")\n",
    "test_category_df, test_categories_dict = load_category_data(raw_data_path /\"test\")\n",
    "    \n",
    "categories = list(train_categories_dict.keys())\n",
    "category_df = pd.concat([train_category_df,validation_category_df,test_category_df])\n",
    "print(f'{category_df.category.nunique()} unique categories found')\n",
    "\n",
    "categories_dict = train_categories_dict\n",
    "\n",
    "category_df.drop_duplicates(subset=['segment'])\n",
    "category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:48:25.138274Z",
     "start_time": "2021-05-11T11:48:25.112643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Data Retention': 0,\n",
       " 'Data Security': 1,\n",
       " 'Do Not Track': 2,\n",
       " 'First Party Collection/Use': 3,\n",
       " 'International and Specific Audiences': 4,\n",
       " 'Introductory/Generic': 5,\n",
       " 'Policy Change': 6,\n",
       " 'Practice not covered': 7,\n",
       " 'Privacy contact information': 8,\n",
       " 'Third Party Sharing/Collection': 9,\n",
       " 'User Access, Edit and Deletion': 10,\n",
       " 'User Choice/Control': 11}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Multilabel labels column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:48:26.343832Z",
     "start_time": "2021-05-11T11:48:26.298968Z"
    }
   },
   "outputs": [],
   "source": [
    "def multilabel_df(category_df):\n",
    "    parent =  category_df.groupby('segment')['category'].unique()\n",
    "    cat_comp_df = pd.DataFrame({'segment':parent.index.values, 'category':parent})\n",
    "    cat_comp_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    labels_ls=[]\n",
    "    for r in cat_comp_df.category:\n",
    "        idx_ls=[]\n",
    "        for c in r:\n",
    "            idx_ls.append(categories_dict[c])   \n",
    "\n",
    "        target = [1] * len(idx_ls)\n",
    "        labels = [0] * len(categories)\n",
    "        for x,y in zip(idx_ls,target):\n",
    "            labels[x] = y\n",
    "        labels_ls.append(labels)\n",
    "\n",
    "    cat_comp_df['label'] = labels_ls\n",
    "    return cat_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:48:28.213925Z",
     "start_time": "2021-05-11T11:48:26.976803Z"
    }
   },
   "outputs": [],
   "source": [
    "train_category_df_comp = multilabel_df(train_category_df)\n",
    "validation_category_df_comp = multilabel_df(validation_category_df)\n",
    "test_category_df_comp  = multilabel_df(test_category_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract from Attribute_Category Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:48:46.399859Z",
     "start_time": "2021-05-11T11:48:31.296387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting from Action First-Party ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/prv/data_utils/data_extraction.py:116: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  attr_cat_df = pd.concat([attr_cat_df, data])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting from Choice Scope ...\n",
      "extracting from Purpose ...\n",
      "extracting from Action Third Party ...\n",
      "extracting from Does or Does Not ...\n",
      "extracting from Notification Type ...\n",
      "extracting from Personal Information Type ...\n",
      "extracting from Audience Type ...\n",
      "extracting from Collection Mode ...\n",
      "extracting from User Type ...\n",
      "extracting from Third Party Entity ...\n",
      "extracting from Access Scope ...\n",
      "extracting from User Choice ...\n",
      "extracting from Identifiability ...\n",
      "extracting from Retention Purpose ...\n",
      "extracting from Change Type ...\n",
      "extracting from Security Measure ...\n",
      "extracting from Access Type ...\n",
      "extracting from Choice Type ...\n",
      "extracting from Do Not Track policy ...\n",
      "extracting from Retention Period ...\n",
      "9 unique categories found\n"
     ]
    }
   ],
   "source": [
    "from data_utils.data_extraction import load_attr_cat_data\n",
    "\n",
    "# Get Attribute Folders\n",
    "attribute_folders = [name for name in os.listdir(attr_data_path) if os.path.isdir(attr_data_path)]\n",
    "\n",
    "attr_cat_df, child_labels_dict = load_attr_cat_data(attr_data_path, attribute_folders=attribute_folders,\n",
    "                                                    categories_dict=categories_dict, include_parent=parent_information,\n",
    "                                                   model=False)\n",
    "rev_child_labels_dict = {}\n",
    "for k in child_labels_dict.keys():\n",
    "    rev_child_labels_dict[child_labels_dict[k]] = k\n",
    "\n",
    "child_labels = list(child_labels_dict.keys())\n",
    "\n",
    "#print(len(attr_cat_df))\n",
    "if parent_information:\n",
    "    print(f'{attr_cat_df.parent_label.nunique()} unique categories found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab Generation\n",
    "Get Vocab from all files in \"raw_data\" and merge with vocab from each attribute folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:48:54.267174Z",
     "start_time": "2021-05-11T11:48:46.402920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vocab ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6819, 6818)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAW VOCAB\n",
    "category_vocab = get_vocab(raw_data_path)\n",
    "len(category_vocab), max(category_vocab.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Extract vocab from every attribute and merge with master vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:49:39.485350Z",
     "start_time": "2021-05-11T11:48:54.269388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n",
      "Generating vocab ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6819, 6818, 6819, 6819)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_vocab = category_vocab\n",
    "\n",
    "# VOCAB EXTRACTION FROM attr_data_path\n",
    "attribute_folders = [name for name in os.listdir(attr_data_path) if os.path.isdir(attr_data_path)]\n",
    "\n",
    "for folder in attribute_folders:\n",
    "    sub_data_path = attr_data_path/folder\n",
    "    vocab = get_vocab(sub_data_path)\n",
    "    \n",
    "    idx = max(master_vocab.values()) + 1\n",
    "    for k in vocab.keys():\n",
    "        try:\n",
    "            master_vocab[k]\n",
    "        except: \n",
    "            master_vocab[k] = idx\n",
    "            idx += 1\n",
    "            \n",
    "len(master_vocab), max(master_vocab.values()), len(set(list(master_vocab.values()))), len(set(list(master_vocab.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the resulting vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:49:39.518740Z",
     "start_time": "2021-05-11T11:49:39.487348Z"
    }
   },
   "outputs": [],
   "source": [
    "save_obj(master_vocab, 'models/master_vocab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:50:14.972957Z",
     "start_time": "2021-05-11T11:49:39.520098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting pretrained embeddings ...\n",
      "Generating embedding matrix ...\n",
      "Some words were missing in the pretrained embedding. 1366 words were not found.\n"
     ]
    }
   ],
   "source": [
    "# MODEL UTILS\n",
    "fasttext_embeddings = get_pretrained_embs(fasttext_model, emb_dim=emb_dim)\n",
    "emb_weights = get_emb_weights(embeddings=fasttext_embeddings, vocab=master_vocab, emb_dim=300, oov_random=True)\n",
    "emb_weights = torch.tensor(emb_weights).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:50:15.057215Z",
     "start_time": "2021-05-11T11:50:14.974697Z"
    }
   },
   "outputs": [],
   "source": [
    "if parent_information:\n",
    "    parent =  attr_cat_df.groupby('parent_label')['attribute'].unique().index\n",
    "    grouped_attr =  attr_cat_df.groupby('parent_label')['attribute'].unique().values\n",
    "\n",
    "    parent_attr_dict = {}\n",
    "    for i,p in enumerate(parent):\n",
    "        parent_attr_dict[p] = grouped_attr[i]\n",
    "    save_obj(parent_attr_dict, 'models/parent_attr_dict')\n",
    "    parent_attr_dict\n",
    "else:\n",
    "    parent_attr_dict=None\n",
    "    print('parent_attr_dict not created as \"parent_information == False\", your attribute data does not contain a parent column, \\\n",
    "you will need to load a saved version or create this dict manually to be able to do inference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Parent Category Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:08:57.470156Z",
     "start_time": "2021-05-11T12:02:19.528700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset ...\n",
      "Num of unique segments: 1738\n",
      "Processing dataset ...\n",
      "Num of unique segments: 955\n",
      "Processing dataset ...\n",
      "Num of unique segments: 1028\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last epoch finished: 300 -- progress: 100.0% -- time: 0.23468099636499884 mins258633 minss\n",
      "Training completed. Total training time: 6.42 mins\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "2977.0 Train Labels\n",
      "1738 Train Segments\n",
      "1587.0 Validation Labels\n",
      "955 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Data Retention                                  0.61      0.86      0.57      87        48        \n",
      "Data Security                                   0.83      0.94      0.77      174       106       \n",
      "Do Not Track                                    0.98      0.95      1.0       18        10        \n",
      "First Party Collection/Use                      0.78      0.82      0.77      713       373       \n",
      "International and Specific Audiences            0.9       0.95      0.86      174       86        \n",
      "Introductory/Generic                            0.73      0.85      0.7       365       211       \n",
      "Policy Change                                   0.88      0.95      0.82      87        58        \n",
      "Practice not covered                            0.63      0.69      0.61      313       163       \n",
      "Privacy contact information                     0.89      0.94      0.84      157       96        \n",
      "Third Party Sharing/Collection                  0.86      0.85      0.86      591       268       \n",
      "User Access, Edit and Deletion                  0.8       0.89      0.74      105       67        \n",
      "User Choice/Control                             0.77      0.76      0.77      296       172       \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.81      0.86      0.78      1738      955       \n",
      "macro avg                                       0.8       0.87      0.78      1738      955       \n",
      "\n",
      "\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "2977.0 Train Labels\n",
      "1738 Train Segments\n",
      "1822.0 Validation Labels\n",
      "1028 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Data Retention                                  0.69      0.87      0.63      87        42        \n",
      "Data Security                                   0.81      0.9       0.76      174       124       \n",
      "Do Not Track                                    1.0       1.0       1.0       18        11        \n",
      "First Party Collection/Use                      0.79      0.81      0.78      713       422       \n",
      "International and Specific Audiences            0.9       0.92      0.88      174       103       \n",
      "Introductory/Generic                            0.7       0.85      0.67      365       247       \n",
      "Policy Change                                   0.84      0.93      0.79      87        62        \n",
      "Practice not covered                            0.64      0.69      0.62      313       186       \n",
      "Privacy contact information                     0.84      0.9       0.8       157       93        \n",
      "Third Party Sharing/Collection                  0.84      0.85      0.84      591       340       \n",
      "User Access, Edit and Deletion                  0.76      0.89      0.7       105       83        \n",
      "User Choice/Control                             0.73      0.73      0.74      296       186       \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.8       0.85      0.77      1738      1028      \n",
      "macro avg                                       0.8       0.86      0.77      1738      1028      \n",
      "\n",
      "\n",
      "***************************************************************************************************\n",
      "***************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# DATA PROCESSING\n",
    "train_cat_tokens, train_cat_parent_labels_arr = process_dataset(df=train_category_df_comp, \n",
    "                                                    vocab=master_vocab, \n",
    "                                                    include_parent=False, \n",
    "                                                    attr_model=False)\n",
    "\n",
    "validation_cat_tokens, validation_cat_parent_labels_arr = process_dataset(df=validation_category_df_comp, \n",
    "                                                    vocab=master_vocab, \n",
    "                                                    include_parent=False, \n",
    "                                                    attr_model=False)\n",
    "test_cat_tokens, test_cat_parent_labels_arr = process_dataset(df=test_category_df_comp, \n",
    "                                                    vocab=master_vocab, \n",
    "                                                    include_parent=False, \n",
    "                                                    attr_model=False)\n",
    "\n",
    "# DATASET\n",
    "train_dataset = PrivacyPoliciesDataset(train_cat_tokens, train_cat_parent_labels_arr, train_categories_dict.keys(),\n",
    "                                 parent_information=None)\n",
    "\n",
    "validation_dataset = PrivacyPoliciesDataset(validation_cat_tokens, validation_cat_parent_labels_arr, validation_categories_dict.keys(),\n",
    "                                 parent_information=None)\n",
    "\n",
    "test_dataset = PrivacyPoliciesDataset(test_cat_tokens, test_cat_parent_labels_arr, test_categories_dict.keys(),\n",
    "                                 parent_information=None)\n",
    "\n",
    "# Load model\n",
    "parent_model = ParentCategoryModel(weights_matrix=emb_weights, num_classes=len(categories),\n",
    "                                   drop=0.2, Co=200, Hu=[100], Ks=[3])\n",
    "\n",
    "# Initialise our Trainer\n",
    "trainer = Trainer()\n",
    "\n",
    "# Initialise the data collator\n",
    "data_collator = DataCollator()\n",
    "\n",
    "# Load model and datasets and start trainins\n",
    "results = trainer.train(parent_model, epochs_num=300, batch_size=40, lr=0.01, weight_decay=0.2, \n",
    "                            train_dataset=train_dataset, validation_dataset=validation_dataset, \n",
    "                            data_collator=data_collator, evaluate_steps=100, verbose=False, \n",
    "                            has_parent=parent_information)\n",
    "\n",
    "print_results(parent_model, data_collator, train_dataset, validation_dataset, threshold=0.5)\n",
    "print('\\n')\n",
    "print_results(parent_model, data_collator, train_dataset, test_dataset, threshold=0.5)\n",
    "print('\\n')\n",
    "print('***'*33)\n",
    "print('***'*33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:38:40.962544Z",
     "start_time": "2021-05-11T12:38:40.919067Z"
    }
   },
   "outputs": [],
   "source": [
    "def multilabel_df(category_df,categories_dict):\n",
    "    \n",
    "    parent =  category_df.groupby('segment')['category'].unique()\n",
    "    cat_comp_df = pd.DataFrame({'segment':parent.index.values, 'category':parent})\n",
    "    cat_comp_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    labels_ls=[]\n",
    "    for r in cat_comp_df.category:\n",
    "        idx_ls=[]\n",
    "        for c in r:\n",
    "            value = len(categories_dict)\n",
    "            if c not in categories_dict.keys():\n",
    "                categories_dict[c]= value\n",
    "            else:\n",
    "                idx_ls.append(categories_dict[c])   \n",
    "\n",
    "        target = [1] * len(idx_ls)\n",
    "        labels = [0] * len(categories_dict)\n",
    "        for x,y in zip(idx_ls,target):\n",
    "            labels[x] = y\n",
    "        labels_ls.append(labels)\n",
    "\n",
    "    cat_comp_df['label'] = labels_ls\n",
    "    return cat_comp_df,categories_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:51:16.133538Z",
     "start_time": "2021-05-11T12:51:15.485049Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_attribute_model(attr, i,epochs_num=30,batch_size=32,lr=0.005):\n",
    "    model_name=f'{attr}_attr_value_model'\n",
    "    print(F'STARTING {i}: {attr} ATTRIBUTE MODEL TRAINING')\n",
    "    raw_data_path = path/'data/child_only'\n",
    "\n",
    "    train_category_df, train_categories_dict = load_category_data(raw_data_path / attr / \"train\")\n",
    "    validation_category_df, validation_categories_dict = load_category_data(raw_data_path / attr / \"validation\")\n",
    "    test_category_df, test_categories_dict = load_category_data(raw_data_path / attr/\"test\")\n",
    "\n",
    "    categories = list(train_categories_dict.keys())\n",
    "    category_df = pd.concat([train_category_df,validation_category_df,test_category_df])\n",
    "    print(f'{category_df.category.nunique()} unique categories found')\n",
    "\n",
    "    train_category_df_comp,train_categories_dict = multilabel_df(train_category_df,train_categories_dict)\n",
    "    validation_category_df_comp ,validation_categories_dict= multilabel_df(validation_category_df,validation_categories_dict)\n",
    "    test_category_df_comp,test_categories_dict  = multilabel_df(test_category_df,test_categories_dict)\n",
    "\n",
    "\n",
    "    # DATA PROCESSING\n",
    "    train_cat_tokens, train_cat_parent_labels_arr = process_dataset(df=train_category_df_comp, \n",
    "                                                        vocab=master_vocab, \n",
    "                                                        include_parent=False, \n",
    "                                                        attr_model=False)\n",
    "\n",
    "    validation_cat_tokens, validation_cat_parent_labels_arr = process_dataset(df=validation_category_df_comp, \n",
    "                                                        vocab=master_vocab, \n",
    "                                                        include_parent=False, \n",
    "                                                        attr_model=False)\n",
    "    test_cat_tokens, test_cat_parent_labels_arr = process_dataset(df=test_category_df_comp, \n",
    "                                                        vocab=master_vocab, \n",
    "                                                        include_parent=False, \n",
    "                                                        attr_model=False)\n",
    "\n",
    "    # DATASET\n",
    "    train_dataset = PrivacyPoliciesDataset(train_cat_tokens, train_cat_parent_labels_arr, train_categories_dict.keys(),\n",
    "                                     parent_information=None)\n",
    "\n",
    "    validation_dataset = PrivacyPoliciesDataset(validation_cat_tokens, validation_cat_parent_labels_arr, validation_categories_dict.keys(),\n",
    "                                     parent_information=None)\n",
    "\n",
    "    test_dataset = PrivacyPoliciesDataset(test_cat_tokens, test_cat_parent_labels_arr, test_categories_dict.keys(),\n",
    "                                     parent_information=None)\n",
    "\n",
    "    # Load model\n",
    "    parent_model = ParentCategoryModel(weights_matrix=emb_weights, num_classes=len(categories),\n",
    "                                       drop=0.2, Co=200, Hu=[100], Ks=[3])\n",
    "\n",
    "    # Initialise our Trainer\n",
    "    trainer = Trainer()\n",
    "\n",
    "    # Initialise the data collator\n",
    "    data_collator = DataCollator()\n",
    "\n",
    "    # Load model and datasets and start trainins\n",
    "    results = trainer.train(parent_model, epochs_num=300, batch_size=40, lr=0.01, weight_decay=0.2, \n",
    "                                train_dataset=train_dataset, validation_dataset=validation_dataset, \n",
    "                                data_collator=data_collator, evaluate_steps=100, verbose=False, \n",
    "                                has_parent=parent_information)\n",
    "\n",
    "    print_results(parent_model, data_collator, train_dataset, validation_dataset, threshold=0.5)\n",
    "    print('\\n')\n",
    "    print_results(parent_model, data_collator, train_dataset, test_dataset, threshold=0.5)\n",
    "    print('\\n')\n",
    "    print('***'*33)\n",
    "    print('***'*33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T14:18:21.057420Z",
     "start_time": "2021-05-11T14:05:50.234297Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING 0: Personal Information Type ATTRIBUTE MODEL TRAINING\n",
      "15 unique categories found\n",
      "Processing dataset ...\n",
      "Num of unique segments: 1023\n",
      "Processing dataset ...\n",
      "Num of unique segments: 541\n",
      "Processing dataset ...\n",
      "Num of unique segments: 603\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last epoch finished: 300 -- progress: 100.0% -- time: 0.10372482209723174 mins6430634 mins\n",
      "Training completed. Total training time: 2.83 mins\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "1922.0 Train Labels\n",
      "1023 Train Segments\n",
      "1032.0 Validation Labels\n",
      "541 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Computer information                            0.87      0.86      0.89      93        49        \n",
      "Contact                                         0.81      0.84      0.79      236       157       \n",
      "Cookies and tracking elements                   0.97      0.97      0.96      215       120       \n",
      "Demographic                                     0.77      0.88      0.72      82        44        \n",
      "Financial                                       0.85      0.82      0.88      72        44        \n",
      "Generic personal information                    0.78      0.79      0.8       481       217       \n",
      "Health                                          0.57      0.99      0.54      52        17        \n",
      "IP address and device IDs                       0.95      0.94      0.97      113       55        \n",
      "Location                                        0.8       0.91      0.74      93        49        \n",
      "Other                                           0.55      0.61      0.56      144       125       \n",
      "Personal identifier                             0.49      0.49      0.5       31        22        \n",
      "Social media data                               0.73      0.87      0.67      31        11        \n",
      "Survey data                                     0.75      0.8       0.72      31        11        \n",
      "User online activities                          0.7       0.69      0.76      226       109       \n",
      "User profile                                    0.67      0.65      0.71      103       33        \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.81      0.81      0.81      1023      541       \n",
      "macro avg                                       0.75      0.81      0.75      1023      541       \n",
      "\n",
      "\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "1922.0 Train Labels\n",
      "1023 Train Segments\n",
      "1110.0 Validation Labels\n",
      "603 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Computer information                            0.77      0.79      0.75      93        55        \n",
      "Contact                                         0.82      0.86      0.8       236       181       \n",
      "Cookies and tracking elements                   0.94      0.96      0.93      215       127       \n",
      "Demographic                                     0.86      0.88      0.84      82        55        \n",
      "Financial                                       0.8       0.79      0.82      72        55        \n",
      "Generic personal information                    0.78      0.78      0.8       481       236       \n",
      "Health                                          0.84      1.0       0.75      52        7         \n",
      "IP address and device IDs                       0.91      0.9       0.92      113       61        \n",
      "Location                                        0.81      0.86      0.78      93        49        \n",
      "Other                                           0.52      0.54      0.52      144       97        \n",
      "Personal identifier                             0.5       0.49      0.5       31        19        \n",
      "Social media data                               0.77      0.77      0.77      31        13        \n",
      "Survey data                                     0.68      0.89      0.62      31        19        \n",
      "User online activities                          0.68      0.68      0.77      226       133       \n",
      "User profile                                    0.66      0.66      0.66      103       61        \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.8       0.8       0.81      1023      603       \n",
      "macro avg                                       0.76      0.79      0.75      1023      603       \n",
      "\n",
      "\n",
      "***************************************************************************************************\n",
      "***************************************************************************************************\n",
      "STARTING 1: Purpose ATTRIBUTE MODEL TRAINING\n",
      "10 unique categories found\n",
      "Processing dataset ...\n",
      "Num of unique segments: 940\n",
      "Processing dataset ...\n",
      "Num of unique segments: 491\n",
      "Processing dataset ...\n",
      "Num of unique segments: 585\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last epoch finished: 300 -- progress: 100.0% -- time: 0.09269034202127946 mins664307 minss\n",
      "Training completed. Total training time: 2.53 mins\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "1949.0 Train Labels\n",
      "940 Train Segments\n",
      "972.0 Validation Labels\n",
      "491 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Additional service/feature                      0.7       0.74      0.68      292       163       \n",
      "Advertising                                     0.92      0.94      0.9       217       113       \n",
      "Analytics/Research                              0.86      0.87      0.85      226       113       \n",
      "Basic service/feature                           0.68      0.68      0.68      348       172       \n",
      "Legal requirement                               0.9       0.9       0.91      94        45        \n",
      "Marketing                                       0.78      0.85      0.75      254       138       \n",
      "Merger/Acquisition                              0.97      0.97      0.97      47        15        \n",
      "Other                                           0.47      0.67      0.51      151       89        \n",
      "Personalization/Customization                   0.79      0.83      0.76      170       64        \n",
      "Service operation and security                  0.74      0.73      0.76      198       89        \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.78      0.81      0.76      940       491       \n",
      "macro avg                                       0.78      0.82      0.78      940       491       \n",
      "\n",
      "\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "1949.0 Train Labels\n",
      "940 Train Segments\n",
      "1202.0 Validation Labels\n",
      "585 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Additional service/feature                      0.71      0.75      0.7       292       182       \n",
      "Advertising                                     0.9       0.92      0.89      217       147       \n",
      "Analytics/Research                              0.85      0.86      0.85      226       141       \n",
      "Basic service/feature                           0.72      0.73      0.71      348       217       \n",
      "Legal requirement                               0.86      0.89      0.83      94        53        \n",
      "Marketing                                       0.79      0.86      0.76      254       170       \n",
      "Merger/Acquisition                              0.96      0.92      1.0       47        24        \n",
      "Other                                           0.51      0.81      0.52      151       82        \n",
      "Personalization/Customization                   0.84      0.9       0.79      170       88        \n",
      "Service operation and security                  0.76      0.77      0.76      198       129       \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.8       0.84      0.77      940       585       \n",
      "macro avg                                       0.79      0.84      0.78      940       585       \n",
      "\n",
      "\n",
      "***************************************************************************************************\n",
      "***************************************************************************************************\n",
      "STARTING 2: Does or Does Not ATTRIBUTE MODEL TRAINING\n",
      "2 unique categories found\n",
      "Processing dataset ...\n",
      "Num of unique segments: 1039\n",
      "Processing dataset ...\n",
      "Num of unique segments: 528\n",
      "Processing dataset ...\n",
      "Num of unique segments: 606\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last epoch finished: 300 -- progress: 100.0% -- time: 0.1012974057816832 mins34994096 mins\n",
      "Training completed. Total training time: 2.77 mins\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "1131.0 Train Labels\n",
      "1039 Train Segments\n",
      "579.0 Validation Labels\n",
      "528 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Does                                            0.7       0.82      0.64      998       513       \n",
      "Does Not                                        0.76      0.93      0.7       146       74        \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.95      0.94      0.95      1039      528       \n",
      "macro avg                                       0.73      0.88      0.67      1039      528       \n",
      "\n",
      "\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "1131.0 Train Labels\n",
      "1039 Train Segments\n",
      "670.0 Validation Labels\n",
      "606 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Does                                            0.83      0.83      0.83      998       594       \n",
      "Does Not                                        0.74      0.9       0.69      146       85        \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.95      0.95      0.95      1039      606       \n",
      "macro avg                                       0.79      0.87      0.76      1039      606       \n",
      "\n",
      "\n",
      "***************************************************************************************************\n",
      "***************************************************************************************************\n",
      "STARTING 3: Action First-Party ATTRIBUTE MODEL TRAINING\n",
      "9 unique categories found\n",
      "Processing dataset ...\n",
      "Num of unique segments: 572\n",
      "Processing dataset ...\n",
      "Num of unique segments: 285\n",
      "Processing dataset ...\n",
      "Num of unique segments: 339\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last epoch finished: 300 -- progress: 100.0% -- time: 0.04597504951181074 mins7779963 minss\n",
      "Training completed. Total training time: 1.25 mins\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "809.0 Train Labels\n",
      "572 Train Segments\n",
      "404.0 Validation Labels\n",
      "285 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Collect from user on other websites             0.5       0.5       0.5       29        6         \n",
      "Collect in mobile app                           0.63      0.86      0.59      58        18        \n",
      "Collect on mobile website                       0.5       0.49      0.5       18        9         \n",
      "Collect on website                              0.59      0.7       0.59      429       217       \n",
      "Other                                           0.56      0.58      0.56      143       95        \n",
      "Receive from other parts of company/affiliates  0.5       0.49      0.5       12        9         \n",
      "Receive from other service/third-party (named)  0.48      0.47      0.5       41        20        \n",
      "Receive from other service/third-party (unnamed)0.69      0.7       0.68      75        35        \n",
      "Track user on other websites                    0.57      0.59      0.55      35        12        \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.8       0.81      0.79      572       285       \n",
      "macro avg                                       0.56      0.6       0.55      572       285       \n",
      "\n",
      "\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "809.0 Train Labels\n",
      "572 Train Segments\n",
      "483.0 Validation Labels\n",
      "339 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Collect from user on other websites             0.5       0.49      0.5       29        11        \n",
      "Collect in mobile app                           0.69      0.78      0.64      58        17        \n",
      "Collect on mobile website                       0.5       0.5       0.5       18        7         \n",
      "Collect on website                              0.52      0.6       0.54      429       248       \n",
      "Other                                           0.58      0.6       0.58      143       116       \n",
      "Receive from other parts of company/affiliates  0.5       0.49      0.5       12        11        \n",
      "Receive from other service/third-party (named)  0.48      0.45      0.5       41        38        \n",
      "Receive from other service/third-party (unnamed)0.61      0.6       0.63      75        38        \n",
      "Track user on other websites                    0.53      0.6       0.53      35        21        \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.78      0.78      0.77      572       339       \n",
      "macro avg                                       0.54      0.57      0.55      572       339       \n",
      "\n",
      "\n",
      "***************************************************************************************************\n",
      "***************************************************************************************************\n",
      "STARTING 4: Action Third Party ATTRIBUTE MODEL TRAINING\n",
      "5 unique categories found\n",
      "Processing dataset ...\n",
      "Num of unique segments: 540\n",
      "Processing dataset ...\n",
      "Num of unique segments: 249\n",
      "Processing dataset ...\n",
      "Num of unique segments: 307\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last epoch finished: 300 -- progress: 100.0% -- time: 0.04116091551201489 mins7151511 minss\n",
      "Training completed. Total training time: 1.13 mins\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "689.0 Train Labels\n",
      "540 Train Segments\n",
      "342.0 Validation Labels\n",
      "249 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Collect on first party website/app              0.73      0.77      0.71      87        55        \n",
      "Other                                           0.56      0.58      0.55      81        55        \n",
      "Receive/Shared with                             0.85      0.84      0.85      422       177       \n",
      "See                                             0.71      0.83      0.67      33        23        \n",
      "Track on first party website/app                0.79      0.76      0.83      81        38        \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.81      0.82      0.8       540       249       \n",
      "macro avg                                       0.73      0.76      0.72      540       249       \n",
      "\n",
      "\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "689.0 Train Labels\n",
      "540 Train Segments\n",
      "399.0 Validation Labels\n",
      "307 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Collect on first party website/app              0.67      0.68      0.67      87        53        \n",
      "Other                                           0.59      0.59      0.59      81        56        \n",
      "Receive/Shared with                             0.82      0.81      0.83      422       222       \n",
      "See                                             0.68      0.87      0.63      33        34        \n",
      "Track on first party website/app                0.86      0.83      0.91      81        47        \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.81      0.82      0.81      540       307       \n",
      "macro avg                                       0.72      0.75      0.72      540       307       \n",
      "\n",
      "\n",
      "***************************************************************************************************\n",
      "***************************************************************************************************\n",
      "STARTING 5: Third Party Entity ATTRIBUTE MODEL TRAINING\n",
      "6 unique categories found\n",
      "Processing dataset ...\n",
      "Num of unique segments: 535\n",
      "Processing dataset ...\n",
      "Num of unique segments: 249\n",
      "Processing dataset ...\n",
      "Num of unique segments: 313\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last epoch finished: 300 -- progress: 100.0% -- time: 0.040960848745167665 mins6426434 mins\n",
      "Training completed. Total training time: 1.11 mins\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "803.0 Train Labels\n",
      "535 Train Segments\n",
      "374.0 Validation Labels\n",
      "249 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Named third party                               0.75      0.75      0.75      257       123       \n",
      "Other                                           0.49      0.48      0.5       43        13        \n",
      "Other part of company/affiliate                 0.67      0.86      0.63      70        40        \n",
      "Other users                                     0.49      0.48      0.5       17        13        \n",
      "Public                                          0.83      0.93      0.77      27        15        \n",
      "Unnamed third party                             0.62      0.69      0.61      407       182       \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.84      0.84      0.83      535       249       \n",
      "macro avg                                       0.64      0.7       0.63      535       249       \n",
      "\n",
      "\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "803.0 Train Labels\n",
      "535 Train Segments\n",
      "465.0 Validation Labels\n",
      "313 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Named third party                               0.72      0.72      0.72      257       176       \n",
      "Other                                           0.57      0.74      0.55      43        13        \n",
      "Other part of company/affiliate                 0.66      0.76      0.63      70        51        \n",
      "Other users                                     0.5       0.49      0.5       17        13        \n",
      "Public                                          0.88      0.93      0.83      27        22        \n",
      "Unnamed third party                             0.62      0.67      0.62      407       201       \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.82      0.82      0.81      535       313       \n",
      "macro avg                                       0.66      0.72      0.64      535       313       \n",
      "\n",
      "\n",
      "***************************************************************************************************\n",
      "***************************************************************************************************\n",
      "STARTING 6: Retention Period ATTRIBUTE MODEL TRAINING\n",
      "4 unique categories found\n",
      "Processing dataset ...\n",
      "Num of unique segments: 41\n",
      "Processing dataset ...\n",
      "Num of unique segments: 24\n",
      "Processing dataset ...\n",
      "Num of unique segments: 21\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last epoch finished: 300 -- progress: 100.0% -- time: 0.004331473823252835 mins6435917 minss\n",
      "Training completed. Total training time: 0.12 mins\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "53.0 Train Labels\n",
      "41 Train Segments\n",
      "32.0 Validation Labels\n",
      "24 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Indefinitely                                    0.47      0.44      0.5       11        4         \n",
      "Limited                                         0.47      0.57      0.53      26        16        \n",
      "Other                                           0.42      0.36      0.5       8         8         \n",
      "Stated Period                                   0.75      0.91      0.72      12        8         \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.72      0.74      0.71      41        24        \n",
      "macro avg                                       0.53      0.57      0.56      41        24        \n",
      "\n",
      "\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "53.0 Train Labels\n",
      "41 Train Segments\n",
      "25.0 Validation Labels\n",
      "21 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Indefinitely                                    0.45      0.41      0.5       11        5         \n",
      "Limited                                         0.54      0.64      0.57      26        13        \n",
      "Other                                           0.4       0.34      0.5       8         8         \n",
      "Stated Period                                   0.73      0.73      0.73      12        3         \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.69      0.7       0.68      41        21        \n",
      "macro avg                                       0.53      0.53      0.58      41        21        \n",
      "\n",
      "\n",
      "***************************************************************************************************\n",
      "***************************************************************************************************\n",
      "STARTING 7: Access Scope ATTRIBUTE MODEL TRAINING\n",
      "5 unique categories found\n",
      "Processing dataset ...\n",
      "Num of unique segments: 77\n",
      "Processing dataset ...\n",
      "Num of unique segments: 56\n",
      "Processing dataset ...\n",
      "Num of unique segments: 61\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last epoch finished: 300 -- progress: 100.0% -- time: 0.006439677003128826 mins6452777 mins\n",
      "Training completed. Total training time: 0.18 mins\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "113.0 Train Labels\n",
      "77 Train Segments\n",
      "81.0 Validation Labels\n",
      "56 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Other                                           0.53      0.66      0.54      21        12        \n",
      "Other data about user                           0.47      0.44      0.5       20        8         \n",
      "Profile data                                    0.38      0.34      0.44      18        18        \n",
      "Transactional data                              0.49      0.48      0.5       11        4         \n",
      "User account data                               0.7       0.69      0.72      48        44        \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.72      0.78      0.7       77        56        \n",
      "macro avg                                       0.51      0.52      0.54      77        56        \n",
      "\n",
      "\n",
      "Setting model to eval mode ...\n",
      "Extracting data ...\n",
      "Evaluating on train set ...\n",
      "Evaluating on validation set ...\n",
      "calculating scores ...\n",
      "\n",
      "113.0 Train Labels\n",
      "77 Train Segments\n",
      "82.0 Validation Labels\n",
      "61 Validation Segments\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Score per label with 0.5 threshold\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Label                                           F1        Precision Recall    C.Train   C.Validation\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Other                                           0.44      0.42      0.47      21        11        \n",
      "Other data about user                           0.52      0.9       0.54      20        14        \n",
      "Profile data                                    0.63      0.62      0.64      18        12        \n",
      "Transactional data                              0.48      0.46      0.5       11        6         \n",
      "User account data                               0.73      0.72      0.75      48        44        \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "micro avg                                       0.72      0.76      0.7       77        61        \n",
      "macro avg                                       0.56      0.63      0.58      77        61        \n",
      "\n",
      "\n",
      "***************************************************************************************************\n",
      "***************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "attribute_folders = [\"Personal Information Type\",\"Purpose\",\"Does or Does Not\",\"Action First-Party\",\"Action Third Party\",\"Third Party Entity\",\"Retention Period\",\"Access Scope\"]\n",
    "for idx, attr in enumerate(attribute_folders):\n",
    "    train_attribute_model(attr,idx,epochs_num=300,batch_size=40,lr=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
